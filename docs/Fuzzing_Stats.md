# **The Stats Digestion Process**

**Overview**

**The system processes two types of fuzzing statistics (JobRun and TestcaseRun) generated by bots. These stats are stored in a database and can be visualized in a dashboard by configuring **stats_columns** and **stats_column_descriptions** for each fuzzer.**

**Data Flow**

1. **Stats Generation & Storage**
   * **Bots upload JSON stats to **{project name}-bigquery-bucket
   * **Processed into **FuzzerJobRunStats** and **FuzzerTestcaseRunStats** tables**
2. **Backend Processing**
   * **Periodic async task processes raw JSON files**
   * **Updates database with new fuzzing statistics**

**Database Models**

* **FuzzerJobRunStats**: Stores fixed fields like **testcases_executed**, **new_crashes**, **known_crashes**, and **crashes** (JSON)
* **FuzzerTestcaseRunStats**: Stores flexible **custom_stats** (JSON) for testcase-specific metrics

**Dashboard Visualization**

**To visualize stats in the dashboard, each fuzzer can be configured with:**

* **stats_columns**: Defines which metrics to display
* **stats_column_descriptions**: Provides human-readable descriptions

**Example Configuration**

```pgsql


sum(t.number_of_executed_units) as tests_executed,
max(j.new_crashes) as new_crashes,
_EDGE_COV as edge_coverage,
_COV_REPORT as cov_report,
_CORPUS_SIZE as corpus_size,
avg(t.average_exec_per_sec) as avg_exec_per_sec,
avg(t.fuzzing_time_percent) as fuzzing_time_percent,
sum(t.new_units_added) as new_tests_added,
sum(t.new_features) as new_features,
avg(t.crash_count*100) as regular_crash_percent,
avg(t.oom_count*100) as oom_percent,
avg(t.leak_count*100) as leak_percent,
avg(t.timeout_count*100) as timeout_percent,
avg(t.startup_crash_count*100) as startup_crash_percent,
avg(t.log_lines_unwanted) as avg_unwanted_log_lines,
sum(t.actual_duration/3600.0) as total_fuzzing_time_hrs,
_FUZZER_RUN_LOGS as logs,
_CORPUS_BACKUP as corpus_backup,
```

```xml
fuzzer: "Fuzz target"
tests_executed: "Number of testcases executed during this time period"
new_crashes: "Number of new unique crashes observed during this time period"
edge_coverage: "Coverage for this fuzz target (number of edges/total)"
cov_report: "Link to coverage report"
corpus_size: "Size of the minimized corpus generated based on code coverage (number of testcases and total size on disk)"
avg_exec_per_sec: "Average number of testcases executed per second"
fuzzing_time_percent: "Percent of expected fuzzing time that is actually spent fuzzing."
new_tests_added: "New testcases added to the corpus during fuzzing based on code coverage"
new_features: "New coverage features based on new tests added to corpus."
regular_crash_percent: "Percent of fuzzing runs that had regular crashes (other than ooms, leaks, timeouts, startup and bad instrumentation crashes)"
oom_percent: "Percent of fuzzing runs that crashed on OOMs (should be 0)"
leak_percent: "Percent of fuzzing runs that crashed on memory leaks (should be 0)"
timeout_percent: "Percent of fuzzing runs that had testcases timeout (should be 0)"
startup_crash_percent: "Percent of fuzzing runs that crashed on startup (should be 0)"
avg_unwanted_log_lines: "Average number of unwanted log lines in fuzzing runs (should be 0)"
total_fuzzing_time_hrs: "Total time in hours for which the fuzzer(s) ran. Will be lower if fuzzer hits a crash frequently."
logs: "Link to fuzzing logs"
corpus_backup: "Backup copy of the minimized corpus generated based on code coverage"
```

Visualization Details**

* **Source Tables**:
  * **t**: Alias for **FuzzerTestcaseRunStats** (custom stats)
  * **j**: Alias for **FuzzerJobRunStats** (fixed fields)
* **Aggregation Methods**:
  * **sum()**: Totals across runs (e.g., executed units, new tests)
  * **max()**: Maximum value (e.g., new crashes)
  * **avg()**: Averages (e.g., execution speed, percentages)
* **Special Fields**:
  * **Fields prefixed with **_** (e.g., **_EDGE_COV**, **_COV_REPORT**) are assumed to be computed or linked externally**
* **Units**:
  * **Time converted to hours (**actual_duration/3600.0**)**
  * **Percentages multiplied by 100 (e.g., **crash_count*100**)**

**Implementation Notes**

* **Configuration**: Stored per fuzzer, linked via **fuzzer_id**
* **Query Generation**: Backend generates SQL queries based on **stats_columns**
* **Display**: Dashboard renders metrics with descriptions from **stats_column_descriptions**
* **Flexibility**: TestcaseRun custom stats allow for fuzzer-specific metrics while JobRun stats provide standardized crash data
